\documentclass[letterpaper,11pt]{article}

\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage[hidelinks]{hyperref}
\usepackage{xcolor}
\usepackage{fontawesome}
\usepackage{enumitem}
\usepackage{array}
\usepackage{setspace}
\usepackage{multirow}
\usepackage[inkscapelatex=false]{svg}

\singlespacing
% \setstretch{1.1}
% \onehalfspacing

\setlist[itemize]{itemsep=0em, topsep=0em, leftmargin=*}

\definecolor{linkblue}{rgb}{0, 0, 1}


% Adjust margins
\addtolength{\oddsidemargin}{-0.5in}
\addtolength{\evensidemargin}{-0.5in}
\addtolength{\textwidth}{1in}
\addtolength{\topmargin}{-.5in}
\addtolength{\textheight}{1.0in}

\urlstyle{same}

\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}
% Sections formatting, reduced vertical space before and after each section.
\titleformat{\section}{
    \scshape\raggedright\Large 
}{}{0em}{}[\color{black}\titlerule]
\titlespacing*{\section}{0pt}{5pt}{5pt} % left, before-skip, after-skip

%-------------------------Custom commands-------------------------

% Link defaulted to black unless using \linkhref
\newcommand{\linkhref}[2]{\textcolor{linkblue}{\href{#1}{#2}}} 

% Date in small italics
\newcommand{\Date}[1]{\textit{\small #1}}

% Heading with 4 arguments: #1: Title, #2: Location, #3: Subtitle, #4: Date
\newcommand{\heading}[4]{
  \textbf{#1} \hfill #2 \\
  \textit{\small#3} \hfill \Date{#4}
}

% % Heading with 3 arguments: #1: Title, #2: Location, #3: Date
% \newcommand{\simpleheading}[3]{%
%   \noindent
%   \begin{tabular*}{\linewidth}{@{\extracolsep{\fill}} l r}
%     \multirow{2}{*}[0pt]{\textbf{#1}} & #2 \\[-0.2ex]
%                                       & \Date{#3}
%   \end{tabular*}%
% }


\renewcommand{\labelitemi}{$\circ$} % First-level bullet points as circles
\renewcommand{\labelitemii}{$\circ$} % Second-level bullet points as circles

\begin{document}

\begin{tabular} {@{}l}
    \textbf{\href{https://brandonyifanyang.com/}{\Large{Brandon Yifan Yang}}} \\[3pt]
    \faLink \, \linkhref{https://brandonyifanyang.com/}{brandonyifanyang.com} \quad \faEnvelope \, \linkhref{mailto:yang52@seas.upenn.edu}{yang52@seas.upenn.edu} \quad \faGithub \, \linkhref{https://github.com/branyang02}{branyang02}
\end{tabular}


\section{Education}
\begin{itemize}
    \item\heading{%
              \raisebox{-0.2\height}{%
                  \includegraphics[height=1.5em]{../penn-logo.png}%
              }%
              \hspace{0.2em} University of Pennsylvania%
          }{Philadelphia, PA}{M.S.E. in Robotics}{Aug 2025 - May 2027}
    \item \heading{%
              \raisebox{-0.2\height}{%
                  \includegraphics[height=1.5em]{../uva-logo.png}%
              }%
              \hspace{0.2em} University of Virginia%
          }{Charlottesville, VA}{B.S. in Computer Science with Highest Distinction $(3.9/4.0)$}{August 2021 - May 2025}
    \item \textbf{Relevant Coursework}: Robotics$^*$, GPU Programming \& Architecture$^*$, Machine Learning, Reinforcement Learning$^*$, Natural Language Processing$^*$, Probabilistic ML$^*$, Optimization$^*$ \\
          {\footnotesize *Graduate-level courses.}
\end{itemize}

\section{Experience}
\begin{itemize}[label={}, leftmargin=0pt]
    \item \heading{Embodied Intelligence Research Intern}{Beijing, China}{Spirit AI}{May 2025 - Aug 2025}
          \begin{itemize}
              \item Trained and deployed Vision-Language-Action (VLA) model variants in PyTorch on a dual-arm robot, experimenting with contrastive objectives, observation-noise curricula, reduced guidance inputs, and mixture-of-experts (MoE).
              \item Designed and implemented DAgger data-collection pipeline for VLA models, including operator-takeover logic and post-training workflows for scaling corrective demonstrations.
              \item Integrated robotics simulation environments into a unified, reproducible setup, enabling efficient evaluation of VLA models; containerized training and evaluation workflows with Docker and Slurm. Open-sourced codebase and datasets on \linkhref{https://github.com/Robot-VLA/lerobot-vla.git}{GitHub}.
          \end{itemize}
\end{itemize}

\section{Research Experience}
\begin{itemize}[label={}, leftmargin=0pt]
    \item \heading{General Robotics, Automation, Sensing, and Perception Lab, UPenn}{Philadelphia, PA}
          {Advisor: Dinesh Jayaraman, Junyao Shi}{Aug 2025 - Present}
          \begin{itemize}
              \item Designing retrieval-augmented VLA models for robot manipulation (ongoing, target: RSS 2026).
              \item Building scalable data pipeline, training and evaluation infrastructure with Docker, Slurm, JAX, Ray, and Hugging Face on GPU clusters.
          \end{itemize}
    \item \heading{Learning and Interactive Robotics, University of Virginia}{Charlottesville, VA}
          {Advisor: Yen-Ling Kuo}{Aug 2024 - May 2025}
          \begin{itemize}
              \item \textbf{Interpretable Vision-Language-Action Models via Skill Conditioning}
                    \begin{itemize}
                        \item Led \textit{SkillVLA}, a skill-conditioned VLA model for language-conditioned manipulation with improved action interpretability via subgoal instructions and learned skill library.
                        \item Presented as an oral talk at the 2024 UVA LLM Workshop (\linkhref{https://www.brandonyifanyang.com/skillvla.pdf}{slides}), earning the Audience Choice Award (top 3 of 28 presentations).
                    \end{itemize}
              \item \textbf{Contrastive Learning for Robot Manipulation}
                    \begin{itemize}
                        \item Performed contrastive learning over action sequences to learn behavior-grounded visual embeddings, improving visuomotor policies under heterogeneous camera poses and object appearances. (\linkhref{https://class-robot.github.io/}{CoRL 2025})
                        \item Modified simulation environments and trained PyTorch-based visuomotor policies to evaluate learned embeddings.
                    \end{itemize}
          \end{itemize}
    \item \heading{Research Assistant, \href{https://www.collabrobotics.com/}{Collaborative Robotics Lab}, University of Virginia}{Charlottesville, VA}
          {Advisor: Tariq Iqbal}{May 2022 - May 2024}
          \begin{itemize}
              \item \href{https://github.com/branyang02/GLOMA}{\textbf{Grounded Location for Object Manipulation (GLOMA)}} [\linkhref{https://github.com/branyang02/GLOMA}{code}]
                    \begin{itemize}
                        \item Led team of 3 to develop zero-shot image-editing model grounded by language instructions for object relocation and manipulation tasks, designed for downstream robotic applications using goal-conditioned RL and Behavioral Cloning (BC).
                        \item Integrated language grounding with visual perception by using bounding box guidance from pre-trained language models, enabling precise object relocation without external supervision and improving baseline performance by 65\%.
                        \item Collected and annotated custom dataset for fine-tuning pre-trained language and vision models.
                        \item Presented poster at 3 conferences and symposiums.
                    \end{itemize}
              \item \textbf{\href{https://github.com/branyang02/PandaFactory}{Centralized multi-agent RL for Collaborative Tasks}} [\linkhref{https://github.com/branyang02/PandaFactory}{code}]
                    \begin{itemize}
                        \item Developed long-horizon on/offline centralized MARL for robotic bolt screwing tasks.
                        \item Designed and optimized custom reward functions in multi-agent framework for task completion and agent collaboration, improving task success rate by 20\%.
                        \item Deployed and tested custom simulated environments in IsaacGym for training and evaluation.
                    \end{itemize}
          \end{itemize}
\end{itemize}

\section{Publications}
\begin{itemize}[label={}, leftmargin=0pt]
    \item Lee, Sung-Wook, Xuhui Kang, \textbf{Brandon Y. Yang}, and Yen-Ling Kuo. ``Class: Contrastive learning via action sequence supervision for robot manipulation." \\
          In \textit{Conference on Robot Learning}, pp. 4743-4766. PMLR, 2025. \hfill [\linkhref{https://class-robot.github.io/}{Website}][\linkhref{https://arxiv.org/abs/2508.01600}{arXiv}][\linkhref{https://arxiv.org/pdf/2508.01600}{PDF}]
    \item Sethi, Amish*, \textbf{Brandon Y. Yang*}, Yuchen Zheng, Jiani Huang, Jianing Qian, Chris Watson, Junyao Shi, Mayur Naik, and Dinesh Jayaraman. ``Retrieval-Augmented Vision-Language-Action Model". \\
          Ongoing project.
\end{itemize}

\section{Software Projects}
\begin{itemize}[label={}, leftmargin=0pt]
    \item \textbf{openpi-cuda} [\linkhref{https://github.com/branyang02/openpi-cuda}{GitHub}]: Developed custom CUDA kernels via C++/Python bindings to accelerate $\pi_{0.5}$ VLA model inference; achieved 18.5ms latency reduction over baseline PyTorch.
    \item \textbf{\href{https://notie-markdown.vercel.app/}{notie-markdown}} [\linkhref{https://notie-markdown.vercel.app/}{Website}]: Markdown rendering web app with support for equation previewing, graphing, code running, and more. Built with React, TypeScript, Python, Flask. Deployed on Vercel and Heroku.
    \item \textbf{Blogs and Notes} [\linkhref{https://www.brandonyifanyang.com/blog}{blog}, \linkhref{https://www.brandonyifanyang.com/notes}{notes}]: Detailed blog posts and course notes with visualizations, graphs, and code on CS and AI topics, written with notie-markdown.
    \item \textbf{\href{https://github.com/branyang02/smart-oh}{SmartOH}} [\linkhref{https://github.com/branyang02/smart-oh}{GitHub}]: Queue management system designed for office hours. Features real-time queue updates, notifications, and analytics. Built with Next.js, TypeScript, Python, FastAPI. Deployed with CI/CD pipeline on Vercel and AWS EC2.
    \item \textbf{Voy}: Collaborated with 7 non-profits to develop Voy, a volunteer and driver management platform; competed and received \$1000 in funding from UVA's Entrepreneurship Cup. Built with React, Node.js, TypeScript, JavaScript.
\end{itemize}

\section{Skills}
\begin{itemize}[label={}, leftmargin=0pt]
    \item \textbf{Programming Languages}: Python, C/C++, Java, JavaScript, TypeScript, Coq
    \item \textbf{ML + Robotics}: PyTorch, Jax, CUDA, ROS, HuggingFace, IsaacGym, Habitat, RLBench, Maniskill
    \item \textbf{Tools \& Frameworks}: Docker, Slurm, Ray, AWS, Git, CI/CD, React, Next.js
\end{itemize}

\vfill
\noindent\textit{\small Last Updated: \today}
\end{document}
